{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37c25600-0841-40e9-8727-b58251ec64e8",
   "metadata": {},
   "source": [
    "# 2.1.2 Preprocessing data before builing NLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ee81ed-fbb8-4dd5-b213-e94348eb8d51",
   "metadata": {},
   "source": [
    "Scraped title and abstracts that were downloaded in 1.1 as TAC_scraped.csv were ranked offline for relevancy. Articles that mentioned fast drying and corrosion resistance were given 5's. Mention of only one of these aspects were ranked 3. Others, including mention of powder coatings, electrodeposition coatings were ranked 1.\n",
    "\n",
    "This code is designed to merge the title and abstract text into a single column and replace all 5 and 3 rankings with 1 (relevant) and all 1's with 0 (not relevant). Data is then split in to train test and validaiton portions and saved as an npz file for import into the model training code in 3.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290c4c4b-04e1-4616-8351-f66db46f9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e43c6dc-b3eb-40ef-bb84-b667998e89cf",
   "metadata": {},
   "source": [
    "## Import data and remove empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db5028a0-f66b-4243-8c05-ec90f5447670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3935, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import training data\n",
    "Database_file = 'TACScrapedCleanMSDOS.csv'\n",
    "\n",
    "raw_data = pd.read_csv(Database_file, encoding='latin')\n",
    "\n",
    "#combine title and abstracts\n",
    "raw_data['Title_Abstract'] = raw_data['title'].fillna('') + raw_data['Abstracts'].fillna('')\n",
    "\n",
    "#remove other columns\n",
    "data_TA = raw_data[['Title_Abstract', 'Relevant']]\n",
    "\n",
    "data_TA.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1baf054-e6d6-4e5d-a107-b5bd1d7dd542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Title Abstract and label:',\n",
       " 'Two-component polyurethane clear coat kit system ',\n",
       " 1.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample results\n",
    "example = 1\n",
    "'Title Abstract and label:', data_TA['Title_Abstract'][example], data_TA['Relevant'][example]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e644716-4e78-4243-9311-efbe09c26924",
   "metadata": {},
   "source": [
    "## Make the rankings binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7bd76b2-d7d6-46da-a567-8bd5ac9d73e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not relevant: 283 Relevant: 214 Total documents: 497\n"
     ]
    }
   ],
   "source": [
    "data_TA = data_TA.dropna(subset= 'Relevant', ignore_index = True)\n",
    "data_TA_1_to_0 = data_TA.replace({'Relevant' : 1}, 0)\n",
    "data_TA_binary = data_TA_1_to_0.replace({'Relevant' : [3, 5]}, 1)\n",
    "\n",
    "#sample balance\n",
    "print(\n",
    "    'Not relevant:', len(data_TA_binary[data_TA_binary['Relevant'] == 0]),\n",
    "    'Relevant:', len(data_TA_binary[data_TA_binary['Relevant'] == 1]),\n",
    "    'Total documents:', data_TA_binary.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a187bb-f2c6-4d60-aeac-4edc4e92c0ce",
   "metadata": {},
   "source": [
    "## Balance the data by removing excess not relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0df95ff3-7011-44f3-86c3-59f6a2b2b47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not relevant: 214 Relevant: 214\n"
     ]
    }
   ],
   "source": [
    "number_to_remove = len(data_TA_binary[data_TA_binary['Relevant'] == 0]) - len(data_TA_binary[data_TA_binary['Relevant'] == 1])\n",
    "data_binary_remove = data_TA_binary.loc[data_TA_binary['Relevant'] == 0].sample(n = number_to_remove, random_state = 42)\n",
    "data_balanced = data_TA_binary.drop(data_binary_remove.index)\n",
    "data_balanced.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\n",
    "    'Not relevant:', len(data_balanced[data_balanced['Relevant'] == 0]),\n",
    "    'Relevant:', len(data_balanced[data_balanced['Relevant'] == 1])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4818a45-01a4-4777-b984-01123011bbe2",
   "metadata": {},
   "source": [
    "## Split off 10% for test and 10% for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75aa22c5-fae0-4a45-8641-277de512892f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test relevant: 21 Test not relevant: 22\n",
      "val relevant: 19 val not relevant: 19\n",
      "Train relevant: 174 Train not relevant: 173\n",
      "Total test data: 43 Total val data: 38 Total train data: 347\n"
     ]
    }
   ],
   "source": [
    "test_data = data_balanced.sample(frac = 0.1, random_state = 1, ignore_index = False)\n",
    "train_data = data_balanced.drop(test_data.index)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "val_data = train_data.sample(frac = 0.1, random_state = 5, ignore_index = False)\n",
    "train_data_balanced = train_data.drop(val_data.index)\n",
    "val_data.reset_index(drop=True, inplace=True)\n",
    "train_data_balanced.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#sample the new balance of the sets\n",
    "print(\n",
    "    'Test relevant:', len(test_data[test_data['Relevant'] == 1]),\n",
    "    'Test not relevant:', len(test_data[test_data['Relevant'] == 0]))\n",
    "print(\n",
    "    'val relevant:', len(val_data[val_data['Relevant'] == 1]),\n",
    "    'val not relevant:', len(val_data[val_data['Relevant'] == 0]))\n",
    "print(\n",
    "    'Train relevant:', len(train_data_balanced[train_data_balanced['Relevant'] == 1]),\n",
    "    'Train not relevant:', len(train_data_balanced[train_data_balanced['Relevant'] == 0]))\n",
    "print( \n",
    "    'Total test data:', test_data.shape[0],\n",
    "    'Total val data:', val_data.shape[0],\n",
    "    'Total train data:', train_data_balanced.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448f286c-e881-4825-bf68-b15580deee19",
   "metadata": {},
   "source": [
    "## Separate targets and align data type for tensor conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7bf5375-cce4-4278-b692-3027db8b251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets = test_data.pop('Relevant').astype(np.int32)\n",
    "train_targets = train_data_balanced.pop('Relevant').astype(np.int32)\n",
    "val_targets = val_data.pop('Relevant').astype(np.int32)\n",
    "\n",
    "train_data_export = train_data_balanced.to_numpy(copy = True)\n",
    "test_data_export = test_data.to_numpy(copy = True)\n",
    "val_data_export = val_data.to_numpy(copy = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90547ac1-9dc7-4e07-b785-4143fe78868c",
   "metadata": {},
   "source": [
    "## Save the data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd584518-476a-42eb-aebd-df0080563aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('2.1.2.TrainTestValData', \n",
    "         train = train_data_export, train_targets = train_targets, \n",
    "         test = test_data_export, test_targets = test_targets,\n",
    "        val = val_data_export, val_targets = val_targets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63e6951b-2222-43ba-863d-93c2f32ecee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2023-11",
   "language": "python",
   "name": "conda-env-anaconda-ai-2023-11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
